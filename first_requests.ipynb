{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openAI chatGPT first requests\n",
    "Based on ideas from https://www.udemy.com/course/mastering-openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, dirname\n",
    "import openai\n",
    "import dotenv\n",
    "from dotenv import dotenv_values, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = join('..', '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "#openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Examples\n",
    "see https://platform.openai.com/docs/api-reference/completions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7iNptzh2zj6sevg6vCQ6heTD6BTps at 0x7f1146eb6cb0> JSON: {\n",
       "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  \"id\": \"cmpl-7iNptzh2zj6sevg6vCQ6heTD6BTps\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1690812413,\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\nMeow!\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"completion_tokens\": 4,\n",
       "    \"total_tokens\": 8\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"The cat says \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hJ4ErHFIpjgbeoKgTAlPI44vUrdN\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690555754,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n1. The Godfather (1972) \\n2. The Shawshank Redemption (1994)\\n3. Raging Bull (1980)\\n4. Casablanca (1942)\\n5. Citizen Kane (1941)\\n\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"completion_tokens\": 51,\n",
      "    \"total_tokens\": 63\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "1. The Godfather (1972) \n",
      "2. The Shawshank Redemption (1994)\n",
      "3. Raging Bull (1980)\n",
      "4. Casablanca (1942)\n",
      "5. Citizen Kane (1941)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Create a list of the best movies of all time: \",\n",
    "    max_tokens=200, #increase max_tokens\n",
    "    stop=\"6.\" #stop at text 6. (anything after and including 6. will not be returned)\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds like fun! What songs do you like to sing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a chatbot speaking like a toddler. \n",
    "\n",
    "User: Hi, how are you?\n",
    "Chatbot: I'm good. \n",
    "User: Tell me about your family.\n",
    "Chatbot: I have a mommy and a daddy and baby sister and two kitties. \n",
    "User: What do you do for fun?\n",
    "Chatbot: I like to play make-believe with my baby sister. I like to pretend to be doggies and kitties and I like to sing and dance too.\n",
    "User:\n",
    "\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    "    stop=[\"Chatbot:\", \"User:\"] # stop after one response from either user or chatbot\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hL3ge0RoqyE5Yhar5qnS4wZWgdBj\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690563408,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"Make a joke about chickens \\n\\nQ: Why don't chickens like people? \\nA: Because they always get picked on!\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Make a joke about chickens \\nQ: Why did the chicken go to the s\\u00e9ance? \\nA: To get to the other side!\",\n",
      "      \"index\": 1,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Make a joke about chickens \\n\\nQ: Why did the chicken go to the s\\u00e9ance? \\nA: To get to the other side!\",\n",
      "      \"index\": 2,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Make a joke about chickens \\n\\nQ: What did the chicken say when it crossed the playground? \\nA: \\\"Hey everyone, I'm going to be some one's dinner tonight!\\\"\",\n",
      "      \"index\": 3,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Make a joke about chickens \\n\\nQ: What did the chicken say when it crossed the road?\\nA: \\\"Cluck, cluck, get out of my way!\\\"\",\n",
      "      \"index\": 4,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 6,\n",
      "    \"completion_tokens\": 138,\n",
      "    \"total_tokens\": 144\n",
      "  }\n",
      "}\n",
      "###########\n",
      "Make a joke about chickens \n",
      "\n",
      "Q: Why don't chickens like people? \n",
      "A: Because they always get picked on!\n",
      "Make a joke about chickens \n",
      "Q: Why did the chicken go to the s√©ance? \n",
      "A: To get to the other side!\n",
      "Make a joke about chickens \n",
      "\n",
      "Q: Why did the chicken go to the s√©ance? \n",
      "A: To get to the other side!\n",
      "Make a joke about chickens \n",
      "\n",
      "Q: What did the chicken say when it crossed the playground? \n",
      "A: \"Hey everyone, I'm going to be some one's dinner tonight!\"\n",
      "Make a joke about chickens \n",
      "\n",
      "Q: What did the chicken say when it crossed the road?\n",
      "A: \"Cluck, cluck, get out of my way!\"\n"
     ]
    }
   ],
   "source": [
    "#changing number of responses, n\n",
    "#add echo (not billed extra for echo)\n",
    "n=5\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Make a joke about chickens \",\n",
    "    max_tokens=200, #increase max_tokens\n",
    "    n=n,\n",
    "    echo=True\n",
    ")\n",
    "print(response)\n",
    "print(\"###########\")\n",
    "for i in range(0, n):\n",
    "    print(response[\"choices\"][i][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7heLv5Vp3XPZ78WUVVzuNwTMtwpLP\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690637575,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\ntop_movies: The Godfather, The Shawshank Redemption, Casablanca, The Godfather Part II, The Dark Knight, Schindler's List, Pulp Fiction, 12 Angry Men, The Lord of the Rings: The Return of the King, The Good, the Bad and the Ugly, Star Wars, Seven Samurai, Forrest Gump, Inception, Fight Club, The Matrix, Goodfellas\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"completion_tokens\": 89,\n",
      "    \"total_tokens\": 120\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "top_movies: The Godfather, The Shawshank Redemption, Casablanca, The Godfather Part II, The Dark Knight, Schindler's List, Pulp Fiction, 12 Angry Men, The Lord of the Rings: The Return of the King, The Good, the Bad and the Ugly, Star Wars, Seven Samurai, Forrest Gump, Inception, Fight Club, The Matrix, Goodfellas\n"
     ]
    }
   ],
   "source": [
    "#prompt engineering, CSV output\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Create a list of the best movies of all time.  Desired format: top_movies: <comma_separated_list> \",\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7heQDDyE7DWhP5GasIZ72AHeuGnmt\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690637841,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\npython_dict = {\\n    'China': 1433783686,\\n    'India': 1366417754,\\n    'United States': 331002651,\\n    'Indonesia': 269603400,\\n    'Brazil': 211049527\\n}\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 26,\n",
      "    \"completion_tokens\": 62,\n",
      "    \"total_tokens\": 88\n",
      "  }\n",
      "}\n",
      "##########\n",
      "\n",
      "\n",
      "python_dict = {\n",
      "    'China': 1433783686,\n",
      "    'India': 1366417754,\n",
      "    'United States': 331002651,\n",
      "    'Indonesia': 269603400,\n",
      "    'Brazil': 211049527\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#prompt engineering, create python dictionary\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Create a list of the top five most populous countries and earth with their population.  Desired output: <python_dict>\",\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(\"##########\")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7heSTtdhBUXy7uOrMknfJRPPP2Opq\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690637981,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \".\\n\\n{\\n    \\\"China\\\":  1409517397,\\n    \\\"India\\\": 1366417754,\\n    \\\"United States\\\": 331002651,\\n    \\\"Indonesia\\\": 268663640,\\n    \\\"Brazil\\\": 212559417\\n  }\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 33,\n",
      "    \"completion_tokens\": 60,\n",
      "    \"total_tokens\": 93\n",
      "  }\n",
      "}\n",
      "##########\n",
      ".\n",
      "\n",
      "{\n",
      "    \"China\":  1409517397,\n",
      "    \"India\": 1366417754,\n",
      "    \"United States\": 331002651,\n",
      "    \"Indonesia\": 268663640,\n",
      "    \"Brazil\": 212559417\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "#prompt engineering, JSON object\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Create a list of the top five most populous countries on earth with their population.  Desired output: JSON object with name as the key and population as the value\",\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(\"##########\")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping with Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/john/anaconda3/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/john/anaconda3/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/john/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.9.5)\n",
      "Requirement already satisfied: urllib3 in /home/john/anaconda3/lib/python3.7/site-packages (1.25.8)\n",
      "Requirement already satisfied: nltk in /home/john/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /home/john/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/john/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/john/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hwZhSMx4SKm89jKnz2UNaPmAnAiJ\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690707621,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n Marcus Tullius Cicero (January BC - December BC) was a Roman statesman, lawyer, scholar, philosopher, writer and academic skeptic. He created a Latin philosophical vocabulary with neologisms and was considered one of Rome's greatest orators and prose stylists. He suppressed the Catiline conspiracy, championed a return to traditional republican government and was proscribed as an enemy of the state by the Second Triumvirate. His works are influential in global culture and his rediscovery in the 14th century began the Renaissance.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 759,\n",
      "    \"completion_tokens\": 111,\n",
      "    \"total_tokens\": 870\n",
      "  }\n",
      "}\n",
      "##########\n",
      "\n",
      "\n",
      " Marcus Tullius Cicero (January BC - December BC) was a Roman statesman, lawyer, scholar, philosopher, writer and academic skeptic. He created a Latin philosophical vocabulary with neologisms and was considered one of Rome's greatest orators and prose stylists. He suppressed the Catiline conspiracy, championed a return to traditional republican government and was proscribed as an enemy of the state by the Second Triumvirate. His works are influential in global culture and his rediscovery in the 14th century began the Renaissance.\n"
     ]
    }
   ],
   "source": [
    "#Wikipedia Summary\n",
    "\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install urllib3\n",
    "!pip install nltk\n",
    "import urllib\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Cicero').read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\"', '', text)\n",
    "text = re.sub(\"'\", '', text)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "openai_prompt=\"Summarize the following text:\"\n",
    "for i in range(20):\n",
    "    openai_prompt+=sentences[i]\n",
    "    \n",
    "#prompt scraped from wikipedia\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(\"##########\")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/john/anaconda3/lib/python3.7/site-packages (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/john/anaconda3/lib/python3.7/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/john/anaconda3/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/john/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (1.9.5)\n",
      "Requirement already satisfied: urllib3 in /home/john/anaconda3/lib/python3.7/site-packages (1.25.8)\n",
      "Requirement already satisfied: nltk in /home/john/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /home/john/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/john/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/john/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "\n",
      "\n",
      "{\n",
      "  \"flower power\": [\"India Pale Ale\", \"Simcoe, Centennial, Cascade, Ahtanum\", \"6.5%\"],\n",
      "  \"everyday haze\": [\"India Pale Ale\", \"Citra, Mosaic, Lotos\", \"6.9%\"],\n",
      "  \"apricot wheat\": [\"Wheat Ale\", \"Summit\", \"4.3%\"],\n",
      "  \"lakeside lager\": [\"Lager\", \"Hallertau, Mittlefruh, Lublin\", \"5.2%\"],\n",
      "  \"nut brown ale\": [\"Brown Ale\", \"Northern Brewer\", \"4.7%\"],\n",
      "  \"cascazilla\": [\"Red India Pale Ale\", \"Crystal, Chinook, Cascade, Amarillo\", \"6.9%\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Website Menu Items to JSON\n",
    "\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install urllib3\n",
    "!pip install nltk\n",
    "import urllib\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "url = \"https://ithacabeer.com/ithaca-beer-core-beliefs\"\n",
    "req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urllib.request.urlopen(req).read()\n",
    "soup = bs.BeautifulSoup(webpage,'lxml')\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\"', '', text)\n",
    "text = re.sub(\"'\", '', text)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "openai_prompt=\"Extract drinks along with type, hops and ABV from the following text. Desired output: JSON object with food name as the key and type, hops, ABV as values. \"\n",
    "for i in range(len(sentences)):\n",
    "    openai_prompt+=sentences[i]\n",
    "   \n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "#print(response)\n",
    "print(\"##########\")\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot Prompting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hxXSAjL5qnfM4JPQVSz1e3NmBUtg\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690711326,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" Sentiment: 0\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 72,\n",
      "    \"completion_tokens\": 4,\n",
      "    \"total_tokens\": 76\n",
      "  }\n",
      "}\n",
      " Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Classify the following text as negative, neutral, or positive.  \\\n",
    "            Desired Format: -1 negative, 0 neutral, 1 positive \\\n",
    "            Input: Love the Food! \\\n",
    "            Sentiment: 1 \\\n",
    "            Input: Worst food since food went to food town \\\n",
    "            Sentiment: -1 \\\n",
    "            The ambiance was nice, but the food was so-so.  \"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hxh2f5dsAuBxxloUZOHwE8hK8sr3\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690711920,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nAlice is 7 years older than Beth, so Alice is 7 years older than Erica when Erica is 30 years old, since Beth is 5 years older than Erica. Therefore, the difference between the ages of Alice and Erica is 7 years.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 46,\n",
      "    \"completion_tokens\": 49,\n",
      "    \"total_tokens\": 95\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "Alice is 7 years older than Beth, so Alice is 7 years older than Erica when Erica is 30 years old, since Beth is 5 years older than Erica. Therefore, the difference between the ages of Alice and Erica is 7 years.\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Alice is 7 years older than Beth, \\\n",
    "                who is 5 years older than Erica. \\\n",
    "                What is the difference between the ages of Alice and Erica, \\\n",
    "                if Erica is 30 years old? \\\n",
    "                Let's think step by step:\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hxmlC2Gwgy8V7EWq9P0s9Kk8n7Gz\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690712275,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nSpanish: Inserte el texto aqu\\u00ed.\\nPolish: Wstaw tekst tutaj.\\nLatin: Textum hic inserat.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"completion_tokens\": 37,\n",
      "    \"total_tokens\": 57\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "Spanish: Inserte el texto aqu√≠.\n",
      "Polish: Wstaw tekst tutaj.\n",
      "Latin: Textum hic inserat.\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Translate the following text to Spanish, Polish, and Latin \\\n",
    "                Text: Insert text here. \"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hxpTuNAJ5c2rSvjI1prXa9NwgOi1\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690712443,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nShe will love to ski and go to the discotech.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 29,\n",
      "    \"completion_tokens\": 14,\n",
      "    \"total_tokens\": 43\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "She will love to ski and go to the discotech.\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Transform the following text from 1st to 3rd person in future tense\\\n",
    "                Text: I love to ski and go to the discotech. \"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7hxsg4CJ0ZLJFgmfW7gjUvg8Cnpxf\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690712642,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n1. The Godfather \\ud83d\\ude07\\n2. The Shawshank Redemption \\ud83d\\ude4c\\n3. Schindler's List \\ud83d\\udc4f\\n4. Casablanca \\ud83c\\udfac\\n5. Raging Bull \\ud83d\\udc02\\n6. Citizen Kane \\ud83d\\udd70\\n7. Sunset Boulevard \\ud83c\\udf05\\n8. The Wizard of Oz \\ud83c\\udf08\\n9. Apocalypse Now \\ud83d\\udca5\\n10. The Lord of the Rings \\ud83d\\udde1\\ufe0f\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 28,\n",
      "    \"completion_tokens\": 94,\n",
      "    \"total_tokens\": 122\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "1. The Godfather üòá\n",
      "2. The Shawshank Redemption üôå\n",
      "3. Schindler's List üëè\n",
      "4. Casablanca üé¨\n",
      "5. Raging Bull üêÇ\n",
      "6. Citizen Kane üï∞\n",
      "7. Sunset Boulevard üåÖ\n",
      "8. The Wizard of Oz üåà\n",
      "9. Apocalypse Now üí•\n",
      "10. The Lord of the Rings üó°Ô∏è\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Create a list of the best movies of all time.\\\n",
    "                Desired output:  Movie title, transform movie title to emojis.\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7iNOQyT9i7vBmRyYhdUgXy6sZlpSz\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690810710,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n\\\\Lorem\\\\ ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 162,\n",
      "    \"completion_tokens\": 157,\n",
      "    \"total_tokens\": 319\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\\Lorem\\ ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Transform the following text into latex format: \\\n",
    "                Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=200, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-7iNYD7XLS5O1mUYWPfLj0sU1zHvrM\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1690811317,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"                                                          \\n(defun maxPalindrome (A)\\n  (let ((s1 A)\\n\\t(s2 '()))\\n    (setq numpy:table (make-array (list (length A) (length A)) :initial-element 0))\\n    (dolist (i (reverse A))\\n      (push i s2))\\n    ;fill in the top and left rows first \\n    (dotimes (i (length s1))\\n      (if (char-equal (nth i s1) (nth 0 s2))\\n\\t  (setf (numpy:element i 0 numpy:table) 1)))\\n    (dotimes (i (length s1))\\n      (if (char-equal (nth 0 s1) (nth i s2))\\n\\t  (setf (numpy:element 0 i numpy:table) 1)))\\n    ;fill in the table \\n    (dotimes (i (1- (length s1)))\\n      (dotimes (j (1- (length s2)))\\n\\t(if (char-equal (nth i s1) (nth j s2))\\n\\t    (setf (numpy:element i j numpy:table) (+  (numpy:element (1- i) (1- j) numpy:table) 1)))))\\n    (numpy:max numpy:table)))\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 260,\n",
      "    \"completion_tokens\": 316,\n",
      "    \"total_tokens\": 576\n",
      "  }\n",
      "}\n",
      "                                                          \n",
      "(defun maxPalindrome (A)\n",
      "  (let ((s1 A)\n",
      "\t(s2 '()))\n",
      "    (setq numpy:table (make-array (list (length A) (length A)) :initial-element 0))\n",
      "    (dolist (i (reverse A))\n",
      "      (push i s2))\n",
      "    ;fill in the top and left rows first \n",
      "    (dotimes (i (length s1))\n",
      "      (if (char-equal (nth i s1) (nth 0 s2))\n",
      "\t  (setf (numpy:element i 0 numpy:table) 1)))\n",
      "    (dotimes (i (length s1))\n",
      "      (if (char-equal (nth 0 s1) (nth i s2))\n",
      "\t  (setf (numpy:element 0 i numpy:table) 1)))\n",
      "    ;fill in the table \n",
      "    (dotimes (i (1- (length s1)))\n",
      "      (dotimes (j (1- (length s2)))\n",
      "\t(if (char-equal (nth i s1) (nth j s2))\n",
      "\t    (setf (numpy:element i j numpy:table) (+  (numpy:element (1- i) (1- j) numpy:table) 1)))))\n",
      "    (numpy:max numpy:table)))\n"
     ]
    }
   ],
   "source": [
    "openai_prompt = \"Convert the following python code to lisp \\\n",
    "                \\\n",
    "                #bottom-up DP strategy for finding a max palindrome \\\n",
    "                import numpy \\\n",
    "                \\\n",
    "                def maxPalindrome(A): \\\n",
    "                s1 = A \\\n",
    "                s2 = [] \\\n",
    "                numpy.table = numpy.zeros((len(A),len(A))) \\\n",
    "                \\\n",
    "                for i in reversed(A): \\\n",
    "                    s2.append(i) \\\n",
    "                \\\n",
    "                #fill in the top and left rows first \\\n",
    "                for i in range(0, len(s1)): \\\n",
    "                    if s1[i]==s2[0]: \\\n",
    "                        numpy.table[i][0]=1 \\\n",
    "                \\\n",
    "                for i in range(0, len(s1)): \\\n",
    "                    if s1[0]==s2[i]: \\\n",
    "                        numpy.table[0][i]=1 \\\n",
    "                \\\n",
    "                #fill in the table \\\n",
    "                for i in range(1,len(s1)): \\\n",
    "                    for j in range(1, len(s2)): \\\n",
    "                        if s1[i]==s2[j]: \\\n",
    "                            numpy.table[i][j]=1+numpy.table[i-1][j-1] \\\n",
    "                \\\n",
    "                return numpy.max(numpy.table)\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=openai_prompt,\n",
    "    max_tokens=500, #increase max_tokens\n",
    ")\n",
    "print(response)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
